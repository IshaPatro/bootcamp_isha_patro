{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "notebook-title",
   "metadata": {},
   "source": [
    "# NASDAQ LSTM Hyperparameter Tuning\n",
    "\n",
    "This notebook implements automated hyperparameter optimization for LSTM neural networks applied to NASDAQ time series prediction using Optuna framework."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports-section",
   "metadata": {},
   "source": [
    "## Dependencies and Imports\n",
    "\n",
    "Essential libraries for data processing, machine learning, and hyperparameter optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d7ef8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "import os\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-loading-section",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing\n",
    "\n",
    "Load NASDAQ historical data and prepare it for time series modeling with normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-loading",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/HistoricalData.csv')\n",
    "df.rename(columns={'Close/Last':'Close'}, inplace=True)\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df.sort_values(by='Date', ascending=True, inplace=True)\n",
    "series = pd.to_numeric(df['Close'], errors='coerce').dropna().values.reshape(-1,1)\n",
    "scaler = MinMaxScaler()\n",
    "scaled = scaler.fit_transform(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sequence-creation-section",
   "metadata": {},
   "source": [
    "## Sequence Creation Utility\n",
    "\n",
    "Function to create input-output sequences for LSTM training with configurable lookback window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sequence-creation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sequences(arr, look_back):\n",
    "    X, y = [], []\n",
    "    for i in range(look_back, len(arr)):\n",
    "        X.append(arr[i-look_back:i])\n",
    "        y.append(arr[i])\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-evaluation-section",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation Function\n",
    "\n",
    "Comprehensive function that builds, trains, and evaluates LSTM models with given hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model-evaluation",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.8\n",
    "\n",
    "def train_eval(params, save_predictions=False, model_name=None):\n",
    "    look_back = params['look_back']\n",
    "    X, y = make_sequences(scaled, look_back)\n",
    "    split = int(len(X)*train_ratio)\n",
    "    X_train, X_test = X[:split], X[split:]\n",
    "    y_train, y_test = y[:split], y[split:]\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(params['lstm_units'], input_shape=(look_back,1), kernel_regularizer=l2(params['l2_reg']), return_sequences=False))\n",
    "    if params['dropout_rate']>0:\n",
    "        model.add(Dropout(params['dropout_rate']))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=Adam(learning_rate=params['learning_rate']), loss='mse')\n",
    "    \n",
    "    es = EarlyStopping(monitor='val_loss', patience=params['patience'], restore_best_weights=True)\n",
    "    model.fit(X_train, y_train, epochs=params['epochs'], batch_size=params['batch_size'], \n",
    "              validation_split=params['validation_split'], shuffle=params['shuffle'], \n",
    "              callbacks=[es], verbose=0)\n",
    "    \n",
    "    train_pred = model.predict(X_train, verbose=0)\n",
    "    test_pred = model.predict(X_test, verbose=0)\n",
    "    train_actual = scaler.inverse_transform(y_train)\n",
    "    test_actual = scaler.inverse_transform(y_test)\n",
    "    train_pred_actual = scaler.inverse_transform(train_pred)\n",
    "    test_pred_actual = scaler.inverse_transform(test_pred)\n",
    "    \n",
    "    if save_predictions and model_name:\n",
    "        train_dates = df['Date'].iloc[look_back:look_back+len(y_train)]\n",
    "        test_dates = df['Date'].iloc[look_back+len(y_train):look_back+len(y_train)+len(y_test)]\n",
    "        train_df = pd.DataFrame({'Date': train_dates, 'Actual': train_actual.flatten(), 'Predicted': train_pred_actual.flatten()})\n",
    "        test_df = pd.DataFrame({'Date': test_dates, 'Actual': test_actual.flatten(), 'Predicted': test_pred_actual.flatten()})\n",
    "        train_df.to_csv(f'data/processed/{model_name}_train_predictions.csv', index=False)\n",
    "        test_df.to_csv(f'data/processed/{model_name}_test_predictions.csv', index=False)\n",
    "    \n",
    "    train_rmse = float(np.sqrt(mean_squared_error(train_actual, train_pred_actual)))\n",
    "    train_mae = float(mean_absolute_error(train_actual, train_pred_actual))\n",
    "    train_r2 = float(r2_score(train_actual, train_pred_actual))\n",
    "    test_rmse = float(np.sqrt(mean_squared_error(test_actual, test_pred_actual)))\n",
    "    test_mae = float(mean_absolute_error(test_actual, test_pred_actual))\n",
    "    test_r2 = float(r2_score(test_actual, test_pred_actual))\n",
    "    \n",
    "    return {'train_rmse':train_rmse,'train_mae':train_mae,'train_r2':train_r2,\n",
    "            'test_rmse':test_rmse,'test_mae':test_mae,'test_r2':test_r2}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baseline-section",
   "metadata": {},
   "source": [
    "## Baseline Model Evaluation\n",
    "\n",
    "Establish baseline performance with default hyperparameters before optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baseline-evaluation",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = {'look_back':20,'lstm_units':16,'dropout_rate':0.2,'l2_reg':0.0005,\n",
    "           'learning_rate':0.001,'epochs':50,'batch_size':32,'patience':8,\n",
    "           'validation_split':0.2,'shuffle':False}\n",
    "before = train_eval(baseline, save_predictions=True, model_name='baseline')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optuna-objective-section",
   "metadata": {},
   "source": [
    "## Optuna Objective Function\n",
    "\n",
    "Define the optimization objective function with hyperparameter search spaces for Optuna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optuna-objective",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        'look_back': trial.suggest_int('look_back', 15, 30),\n",
    "        'lstm_units': trial.suggest_int('lstm_units', 16, 64),\n",
    "        'dropout_rate': trial.suggest_float('dropout_rate', 0.0, 0.4),\n",
    "        'l2_reg': trial.suggest_float('l2_reg', 0.0, 0.001),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-4, 5e-3, log=True),\n",
    "        'epochs': trial.suggest_int('epochs', 30, 80),\n",
    "        'batch_size': trial.suggest_categorical('batch_size', [16,32,64]),\n",
    "        'patience': trial.suggest_int('patience', 5, 12),\n",
    "        'validation_split': trial.suggest_float('validation_split', 0.1, 0.3),\n",
    "        'shuffle': False\n",
    "    }\n",
    "    metrics = train_eval(params)\n",
    "    return metrics['test_r2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimization-section",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization\n",
    "\n",
    "Execute Optuna study to find optimal hyperparameters maximizing test RÂ² score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optimization",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=60, show_progress_bar=True)\n",
    "best_params = study.best_params\n",
    "best_params['shuffle']=False\n",
    "metrics_after = train_eval(best_params, save_predictions=True, model_name='optimized')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "results-section",
   "metadata": {},
   "source": [
    "## Results Comparison\n",
    "\n",
    "Compare baseline and optimized model performance across all evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "results-comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame([dict(experiment='before',**before), \n",
    "                       dict(experiment='after',**metrics_after)])\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualization-section",
   "metadata": {},
   "source": [
    "## Actual vs Predicted Comparison: Before and After Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparison-plots",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_train = pd.read_csv('data/processed/baseline_train_predictions.csv')\n",
    "baseline_test = pd.read_csv('data/processed/baseline_test_predictions.csv')\n",
    "optimized_train = pd.read_csv('data/processed/optimized_train_predictions.csv')\n",
    "optimized_test = pd.read_csv('data/processed/optimized_test_predictions.csv')\n",
    "\n",
    "baseline_train['Date'] = pd.to_datetime(baseline_train['Date'])\n",
    "baseline_test['Date'] = pd.to_datetime(baseline_test['Date'])\n",
    "optimized_train['Date'] = pd.to_datetime(optimized_train['Date'])\n",
    "optimized_test['Date'] = pd.to_datetime(optimized_test['Date'])\n",
    "\n",
    "os.makedirs('deliverables/hyperparameter_tuning_images', exist_ok=True)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(20, 12))\n",
    "fig.suptitle('Actual vs Predicted: Before and After Hyperparameter Tuning', fontsize=16, fontweight='bold')\n",
    "\n",
    "axes[0, 0].plot(baseline_train['Date'], baseline_train['Actual'], label='Actual', color='blue', alpha=0.7)\n",
    "axes[0, 0].plot(baseline_train['Date'], baseline_train['Predicted'], label='Predicted', color='red', alpha=0.7)\n",
    "axes[0, 0].set_title('Baseline Model - Training Set', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Date')\n",
    "axes[0, 0].set_ylabel('Price')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[0, 1].plot(baseline_test['Date'], baseline_test['Actual'], label='Actual', color='blue', alpha=0.7)\n",
    "axes[0, 1].plot(baseline_test['Date'], baseline_test['Predicted'], label='Predicted', color='red', alpha=0.7)\n",
    "axes[0, 1].set_title('Baseline Model - Test Set', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Date')\n",
    "axes[0, 1].set_ylabel('Price')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1, 0].plot(optimized_train['Date'], optimized_train['Actual'], label='Actual', color='blue', alpha=0.7)\n",
    "axes[1, 0].plot(optimized_train['Date'], optimized_train['Predicted'], label='Predicted', color='red', alpha=0.7)\n",
    "axes[1, 0].set_title('Optimized Model - Training Set', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Date')\n",
    "axes[1, 0].set_ylabel('Price')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1, 1].plot(optimized_test['Date'], optimized_test['Actual'], label='Actual', color='blue', alpha=0.7)\n",
    "axes[1, 1].plot(optimized_test['Date'], optimized_test['Predicted'], label='Predicted', color='red', alpha=0.7)\n",
    "axes[1, 1].set_title('Optimized Model - Test Set', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Date')\n",
    "axes[1, 1].set_ylabel('Price')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('deliverables/hyperparameter_tuning_images/before_after_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "baseline_combined = pd.concat([baseline_train, baseline_test]).sort_values('Date')\n",
    "optimized_combined = pd.concat([optimized_train, optimized_test]).sort_values('Date')\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 6))\n",
    "fig.suptitle('Full Timeline Comparison: Before vs After Hyperparameter Tuning', fontsize=16, fontweight='bold')\n",
    "\n",
    "axes[0].plot(baseline_combined['Date'], baseline_combined['Actual'], label='Actual', color='blue', alpha=0.7)\n",
    "axes[0].plot(baseline_combined['Date'], baseline_combined['Predicted'], label='Predicted', color='red', alpha=0.7)\n",
    "axes[0].set_title('Baseline Model - Full Timeline', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Date')\n",
    "axes[0].set_ylabel('Price')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(optimized_combined['Date'], optimized_combined['Actual'], label='Actual', color='blue', alpha=0.7)\n",
    "axes[1].plot(optimized_combined['Date'], optimized_combined['Predicted'], label='Predicted', color='red', alpha=0.7)\n",
    "axes[1].set_title('Optimized Model - Full Timeline', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Date')\n",
    "axes[1].set_ylabel('Price')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('deliverables/hyperparameter_tuning_images/full_timeline_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bootcamp_venv",
   "language": "python",
   "name": "bootcamp_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
